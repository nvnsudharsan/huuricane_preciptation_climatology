{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a0d19-a601-4528-b91b-fb2cd4f9504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from geopy import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a314a01-0db4-4f80-a7c7-3f7e74e73a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from shapely.prepared import prep\n",
    "import shapely.geometry as sgeom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081108ee-1954-47e4-b4c7-8987678daa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hurdat2_land.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e83f199-e9d8-42ee-ac03-c13145d334a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "bth = df[df['datetime']>datetime(2000,6,24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdde52d-018b-47e2-8743-f7978fb65b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gom_coords = [(25.68,-97.23),\n",
    "              (26.37,-97.38),\n",
    "              (26.87,-97.47),\n",
    "              (27.34,-97.39),\n",
    "              (28.0,-96.9),\n",
    "              (28.27,-96.46),\n",
    "              (28.52,-96.1),\n",
    "              (28.76,-95.54),\n",
    "              (29.1,-95.06),\n",
    "              (29.49,-94.49),\n",
    "              (29.63,-94),\n",
    "              (29.75,-93.59),\n",
    "              (29.77,-93.17),\n",
    "              (29.63,-92.7),\n",
    "              (29.48,-92.08),\n",
    "              (29.18,-91.18),\n",
    "              (29.06,89.99),\n",
    "              (29.13,-89.23),\n",
    "              (29.76,-89.4),\n",
    "              (30.28,-88.76),\n",
    "              (30.21,-87.88),\n",
    "              (30.33,-87.3),\n",
    "              (30.4,-86.77),\n",
    "              (30.34,-86.29),\n",
    "              (30.1,-85.73),\n",
    "              (29.94,-85.45),\n",
    "              (26.69,-85.30),\n",
    "              (29.75,-84.83),\n",
    "              (29.9,-84.48),\n",
    "              (30.1,-84.22),\n",
    "              (30.04,-83.94),\n",
    "              (29.89,-83.66),\n",
    "              (29.47,-83.29),\n",
    "              (29.03,-82.77),\n",
    "              (28.41,-82.68),\n",
    "              (27.81,-82.8),\n",
    "              (27.4,-82.59),\n",
    "              (27.12,-82.47),\n",
    "              (26.66,-82.25),\n",
    "              (26.4,-82.06),\n",
    "              (26.24,-81.82),\n",
    "              (25.93,-81.74),\n",
    "              (25.83,-81.47),\n",
    "              (25.64,-81.25),\n",
    "              (25.41,-81.15),\n",
    "              (25.2,-81.16),\n",
    "              (24.54,-81.81),\n",
    "              (24.69,-81.1),\n",
    "              (24.89,-80.64),\n",
    "              (25.15,-80.35),\n",
    "              (25.42,-80.21)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf79757-ed94-4dde-b358-9f307f859782",
   "metadata": {},
   "outputs": [],
   "source": [
    "texas_coords = [\n",
    "    (25.9,-97.13),\n",
    "    (26.36,-99.05),\n",
    "    (27.58,-99.54),\n",
    "    (29.51,-101.2),\n",
    "    (29.78,-101.6),\n",
    "    (29.72,-102.66),\n",
    "    (28.98,-103.16),\n",
    "    (29.36,-104.1),\n",
    "    (29.66,-104.52),\n",
    "    (30.21,-104.7),\n",
    "    (30.6,-104.94),\n",
    "    (31.77,-106.51),\n",
    "    (31.87,-106.63),\n",
    "    (32,-106.62),\n",
    "    (32,-103.06),\n",
    "    (36.5,-103.05),\n",
    "    (36.5,-100),\n",
    "    (34.6,-100),\n",
    "    (34.6,-99.97),\n",
    "    (34.5,-99.95),\n",
    "    (34.5,-99.9),\n",
    "    (34.37,-99.66),\n",
    "    (34.41,-99.58),\n",
    "    (34.37,-99.4),\n",
    "    (34.46,-99.37),\n",
    "    (33.55,-94.05),\n",
    "    (32,-94),\n",
    "    (31.18,-93.5),\n",
    "    (30.79,-93.57),\n",
    "    (30.49,-93.71),\n",
    "    (30.14,-93.7),\n",
    "    (29.81,-93.925),\n",
    "    (29.68,-93.84),\n",
    "    (29.68,-94.028),\n",
    "    (29.4,-94.7),\n",
    "    (29.3,-94.74),\n",
    "    (28.86,-95.38),\n",
    "    (28.36,-96.37),\n",
    "    (27.56,-97.22),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d759e12b-5cb6-4c30-bf59-fd2b5bf551ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_id =[]\n",
    "for storm_number in bth['Number'].unique():\n",
    "    storm = bth[bth['Number'] == storm_number]\n",
    "    for index in storm.index:\n",
    "        for point in texas_coords: # change the coords accordingly\n",
    "            if distance.geodesic((storm['Lat'][index],storm['Lon'][index]), point).miles < 60.1: # 60 miles\n",
    "                storm_id.append(storm_number)\n",
    "storm_id = pd.DataFrame(storm_id, columns=['storm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ac4b9-e424-4449-a624-16356aa55514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b1c4c-1d48-4512-bbac-3c1af0e904c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_circular_mask(data, radius_km, grid_resolution_km):\n",
    "    \"\"\"\n",
    "    Apply a circular mask to the data array.\n",
    "\n",
    "    Parameters:\n",
    "        data (ndarray): 2D precipitation data array.\n",
    "        radius_km (float): Radius for the circular mask in kilometers.\n",
    "        grid_resolution_km (float): Resolution of the grid in kilometers per cell.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Masked data with values outside the radius set to NaN.\n",
    "    \"\"\"\n",
    "    center = (data.shape[0] // 2, data.shape[1] // 2)\n",
    "    y, x = np.ogrid[:data.shape[0], :data.shape[1]]\n",
    "    distance_from_center = np.sqrt((x - center[1]) ** 2 + (y - center[0]) ** 2)\n",
    "    radius_in_cells = radius_km / grid_resolution_km\n",
    "    mask = distance_from_center <= radius_in_cells\n",
    "    masked_data = np.where(mask, data, np.nan)\n",
    "    return masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0b2f6-5b0e-4d65-8212-8c0ee9fb127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shared_colorbar():\n",
    "    \"\"\"\n",
    "    Create a shared colorbar for all plots with distinct colors for each millimeter from 1 to 12.\n",
    "    Values above 12 mm will be capped at 12 mm.\n",
    "\n",
    "    Returns:\n",
    "        cmap, norm: Colormap and normalization for the plots.\n",
    "    \"\"\"\n",
    "    levels = np.arange(0, 15, 0.5)\n",
    "    base_cmap = plt.get_cmap('nipy_spectral_r', len(levels) - 1)\n",
    "\n",
    "    # Modify the base colormap to replace black with magenta\n",
    "    colors = base_cmap(np.arange(base_cmap.N))\n",
    "    colors[-1] = [0.35, 0, 0.52, 1]  # RGBA for magenta\n",
    "    cmap = ListedColormap(colors)\n",
    "\n",
    "    norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
    "    return cmap, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551b434-6f9c-4332-9414-2650e7fd528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precip_heatmap(composite_precip, category, cmap, norm):\n",
    "    \"\"\"\n",
    "    Plot composite precipitation heatmap for a given category.\n",
    "\n",
    "    Parameters:\n",
    "        composite_precip (ndarray): Composite precipitation data.\n",
    "        category (str): Storm category (e.g., HU, TD, TS).\n",
    "        cmap: Colormap for the plot.\n",
    "        norm: Normalization for the plot.\n",
    "    \"\"\"\n",
    "    # Apply circular mask (assuming 10 km grid resolution)\n",
    "    circular_precip = apply_circular_mask(composite_precip, radius_km=700, grid_resolution_km=10)\n",
    "\n",
    "    # Cap precipitation values at 12 mm\n",
    "    circular_precip = np.minimum(circular_precip, 12)\n",
    "\n",
    "    # Plot the precipitation heatmap\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    ax.set_title(f\"Composite Precipitation Heatmap for {category}\")\n",
    "    heatmap = ax.imshow(circular_precip, cmap=cmap, norm=norm, origin='lower')\n",
    "\n",
    "    # Draw circular boundaries and add radius markings\n",
    "    center = (circular_precip.shape[0] // 2, circular_precip.shape[1] // 2)\n",
    "    for radius_km in range(100, 700, 100):\n",
    "        radius_in_cells = radius_km / 10\n",
    "        circle = plt.Circle(center[::-1], radius_in_cells, color='black', fill=False, linestyle='-', linewidth=0.5, alpha=0.8)\n",
    "        ax.add_artist(circle)\n",
    "        ax.text(center[1], center[0] - radius_in_cells - 5, f\"{radius_km} km\", color='black', fontsize=6, ha='center', va='bottom')\n",
    "\n",
    "    # Draw a horizontal line through the center\n",
    "    ax.axhline(y=center[0], color='black', linestyle='-', linewidth=0.5, alpha=0.8)\n",
    "\n",
    "    # Draw a vertical line through the center\n",
    "    ax.axvline(x=center[1], color='black', linestyle='-', linewidth=0.5, alpha=0.8)\n",
    "    \n",
    "    # Remove x and y axis\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add shared colorbar below the plot\n",
    "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Precipitation (mm/hr)\")\n",
    "\n",
    "    figname = f'composite_precipitation_{category}.png' # change the name according to the territory considered\n",
    "    # Save the plot\n",
    "    plt.savefig(figname, dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ce46d-e349-46e0-8afb-a0d9280baeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all files in the directory and create composites\n",
    "def process_directory(directory, bth, storm_ids):\n",
    "    \"\"\"\n",
    "    Process all NetCDF files in the directory to create composite heatmaps for categories based on storm type and maximum sustained speed.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Path to the directory containing NetCDF files.\n",
    "        bth (pd.DataFrame): DataFrame containing storm metadata, including maximum sustained wind speed.\n",
    "    \"\"\"\n",
    "    # Ensure the datetime column is in the correct format\n",
    "    bth.loc[:, 'datetime'] = pd.to_datetime(bth['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Filter storms by provided storm IDs\n",
    "    bth = bth[bth['Number'].isin(storm_ids['storm_id'])] #if using whole data, comment this line\n",
    "\n",
    "    # Classify storms based on their type and maximum sustained wind speed\n",
    "    tropical_depressions = bth[bth['Status'] == 'TD']\n",
    "    tropical_storms = bth[bth['Status'] == 'TS']\n",
    "    high_category_hurricanes = bth[(bth['Status'] == 'HU') & (bth['Maximum Sustained Wind'] > 95)]\n",
    "    low_category_hurricanes = bth[(bth['Status'] == 'HU') & (bth['Maximum Sustained Wind'] <= 95)]\n",
    "\n",
    "    categories = {\n",
    "        \"Tropical_Depression\": tropical_depressions,\n",
    "        \"Tropical_Storm\": tropical_storms,\n",
    "        \"Category_3_4_5_Hurricanes\": high_category_hurricanes,\n",
    "        \"Category_1_2_Hurricanes\": low_category_hurricanes\n",
    "    }\n",
    "\n",
    "    # Create a shared colormap and normalization\n",
    "    cmap, norm = create_shared_colorbar()\n",
    "\n",
    "    for category_name, storms in categories.items():\n",
    "        composite_precip = None\n",
    "        count = 0\n",
    "\n",
    "        print(f\"Processing category: {category_name}\")\n",
    "\n",
    "        for _, storm in storms.iterrows():\n",
    "            storm_id = storm['Number']\n",
    "            datetime_str = storm['datetime'].strftime('%m_%d_%H_%M')\n",
    "\n",
    "            # Match the corresponding NetCDF file\n",
    "            nc_file_pattern = f\"{storm_id}_{datetime_str}_.*\\.nc\"\n",
    "            matching_files = [f for f in os.listdir(directory) if re.search(nc_file_pattern, f)]\n",
    "\n",
    "            if not matching_files:\n",
    "                #print(f\"No matching files for storm {storm_id} at {datetime_str}\")\n",
    "                continue\n",
    "\n",
    "            for file in matching_files:\n",
    "                #print(f\"Processing file: {file}\")\n",
    "                file_path = os.path.join(directory, file)\n",
    "                data = xr.open_dataset(file_path)\n",
    "                precip = data['precip'].values\n",
    "\n",
    "                # Replace negative values with zero\n",
    "                precip[precip < 0] = 0\n",
    "\n",
    "                # Initialize composite\n",
    "                if composite_precip is None:\n",
    "                    composite_precip = precip\n",
    "                else:\n",
    "                    composite_precip += precip\n",
    "\n",
    "                count += 1\n",
    "\n",
    "        if count > 0:\n",
    "            composite_precip /= count\n",
    "            plot_precip_heatmap(composite_precip, category_name, cmap, norm)\n",
    "        else:\n",
    "            print(f\"No data to plot for category: {category_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48a0a0-13dd-440f-89b9-137a27f99583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without considering the inland and offshore subcategories\n",
    "directory = \"/scratch/09295/naveens/rotated_data_hurricane/unmasked/\"  # Replace with the actual directory path\n",
    "process_directory(directory, bth, storm_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f8424-b288-4569-abd7-166299f91b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#considering the subcategories\n",
    "def process_directory(directory, bth, storm_ids):\n",
    "    \"\"\"\n",
    "    Process all NetCDF files in the directory to create composite heatmaps for categories based on storm type and maximum sustained speed.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Path to the directory containing NetCDF files.\n",
    "        bth (pd.DataFrame): DataFrame containing storm metadata, including maximum sustained wind speed.\n",
    "        storm_ids (pd.DataFrame): DataFrame containing the storm IDs to process.\n",
    "    \"\"\"\n",
    "    # Filter storms by provided storm IDs\n",
    "    bth = bth[bth['Number'].isin(storm_ids['storm_id'])]\n",
    "\n",
    "    # Classify storms based on their type and maximum sustained wind speed\n",
    "    tropical_depressions = bth[bth['Status'] == 'TD']\n",
    "    tropical_storms = bth[bth['Status'] == 'TS']\n",
    "    high_category_hurricanes = bth[(bth['Status'] == 'HU') & (bth['Maximum Sustained Wind'] > 95)]\n",
    "    low_category_hurricanes = bth[(bth['Status'] == 'HU') & (bth['Maximum Sustained Wind'] <= 95)]\n",
    "\n",
    "    inland = bth[(bth['land_minus_350'] == 1) & (bth['land_plus_350'] == 1) & (bth['inland'] == 1)]\n",
    "    offshore = bth[(bth['land_minus_350'] == 0) & (bth['land_plus_350'] == 0) & (bth['inland'] == 0)]\n",
    "    transition = bth[(bth['land_minus_350'] == 0) & (bth['land_plus_350'] == 1) & (bth['inland'] == 0)]\n",
    "\n",
    "    categories = {\n",
    "        \"Tropical_Depression\": tropical_depressions,\n",
    "        \"Tropical_Storm\": tropical_storms,\n",
    "        \"Category_3_4_5_Hurricanes\": high_category_hurricanes,\n",
    "        \"Category_1_2_Hurricanes\": low_category_hurricanes\n",
    "    }\n",
    "\n",
    "    subcategories = {\n",
    "        \"Inland\": inland,\n",
    "        \"Offshore\": offshore,\n",
    "        \"Transition\": transition\n",
    "    }\n",
    "\n",
    "    # Create a shared colormap and normalization\n",
    "    cmap, norm = create_shared_colorbar()\n",
    "\n",
    "    for category_name, storms in categories.items():\n",
    "        for subcategory_name, subcategory_storms in subcategories.items():\n",
    "            composite_precip = None\n",
    "            count = 0\n",
    "\n",
    "            print(f\"Processing {category_name} - {subcategory_name}\")\n",
    "\n",
    "            filtered_storms = storms.merge(subcategory_storms, how='inner', on=['Number', 'datetime', 'Status'])\n",
    "\n",
    "            for _, storm in filtered_storms.iterrows():\n",
    "                storm_id = storm['Number']\n",
    "                datetime_str = storm['datetime'].strftime('%m_%d_%H_%M')\n",
    "\n",
    "                # Match the corresponding NetCDF file\n",
    "                nc_file_pattern = f\"{storm_id}_{datetime_str}_.*\\.nc\"\n",
    "                matching_files = [f for f in os.listdir(directory) if re.search(nc_file_pattern, f)]\n",
    "\n",
    "                if not matching_files:\n",
    "                    #print(f\"No matching files for storm {storm_id} at {datetime_str}\")\n",
    "                    continue\n",
    "\n",
    "                for file in matching_files:\n",
    "                    #print(f\"Processing file: {file}\")\n",
    "                    file_path = os.path.join(directory, file)\n",
    "                    data = xr.open_dataset(file_path)\n",
    "                    precip = data['precip'].values\n",
    "\n",
    "                    # Replace negative values with zero\n",
    "                    precip[precip < 0] = 0\n",
    "\n",
    "                    # Initialize composite\n",
    "                    if composite_precip is None:\n",
    "                        composite_precip = precip\n",
    "                    else:\n",
    "                        composite_precip += precip\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            if count > 0:\n",
    "                composite_precip /= count\n",
    "                combined_category = f\"{category_name}_{subcategory_name}\"\n",
    "                plot_precip_heatmap(composite_precip, combined_category, cmap, norm)\n",
    "            else:\n",
    "                print(f\"No data to plot for {category_name} - {subcategory_name}\")\n",
    "\n",
    "directory = \"/scratch/09295/naveens/rotated_data_hurricane/unmasked/\"  # Replace with the actual directory path\n",
    "process_directory(directory, bth,storm_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee163e-9105-4e9d-a693-79e57d098d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748c676-11fe-4661-81c0-41eab37fa3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_radial_profiles(all_profiles, max_radius_km=600):\n",
    "    \"\"\"\n",
    "    Plot radial profiles of precipitation for all categories in the same plot.\n",
    "\n",
    "    Parameters:\n",
    "        all_profiles (dict): Dictionary with categories as keys and radial profile data as values.\n",
    "        max_radius_km (int): Maximum radius in kilometers for the x-axis.\n",
    "    \"\"\"\n",
    "    max_radius_cells = max_radius_km / 10  # Convert radius from km to grid cells\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    category_labels = {\n",
    "        \"Tropical_Depression\": \"Tropical Depression\",\n",
    "        \"Tropical_Storm\": \"Tropical Storm\",\n",
    "        \"Category_1_2_Hurricanes\": \"Hurricane 1 & 2\",\n",
    "        \"Category_3_4_5_Hurricanes\": \"Hurricane 3, 4 & 5\"\n",
    "    }\n",
    "\n",
    "    for category, profile_data in all_profiles.items():\n",
    "        mean_values, lower_bound, upper_bound = profile_data\n",
    "        radial_distances_km = np.arange(len(mean_values)) * 10  # Convert grid cells to km\n",
    "\n",
    "        plt.plot(radial_distances_km, mean_values, label=category_labels.get(category, category), linewidth=1.5)\n",
    "        plt.fill_between(radial_distances_km, lower_bound, upper_bound, alpha=0.2)\n",
    "\n",
    "    plt.xlabel(\"Distance from Center (km)\")\n",
    "    plt.ylabel(\"Precipitation (mm/hr)\")\n",
    "    plt.title(\"Radial Precipitation Profiles for All Categories\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    figname = \"combined_radial_profiles.png\" #change the name according to the territory\n",
    "    plt.savefig(figname, dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c006c1b-e52f-4da6-8fcc-c272a9626063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory_for_profiles(directory, bth, storm_ids):\n",
    "    \"\"\"\n",
    "    Process all NetCDF files in the directory to create radial profiles for multiple categories.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Path to the directory containing NetCDF files.\n",
    "        bth (pd.DataFrame): DataFrame containing storm metadata, including maximum sustained wind speed.\n",
    "        storm_ids (pd.DataFrame): DataFrame containing the storm IDs to process.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of radial profiles for each category.\n",
    "    \"\"\"\n",
    "    # Filter storms by provided storm IDs\n",
    "    #bth = bth[bth['Number'].isin(storm_ids['storm_id'])]\n",
    "\n",
    "    # Classify storms based on their type and maximum sustained wind speed\n",
    "    tropical_depressions = bth[bth['Status'] == 'TD']\n",
    "    tropical_storms = bth[bth['Status'] == 'TS']\n",
    "    high_category_hurricanes = bth[(bth['Status'] == 'HU') & (bth['Maximum Sustained Wind'] > 95)]\n",
    "    low_category_hurricanes = bth[(bth['Status'] == 'HU') & (bth['Maximum Sustained Wind'] <= 95)]\n",
    "\n",
    "    categories = {\n",
    "        \"Tropical_Depression\": tropical_depressions,\n",
    "        \"Tropical_Storm\": tropical_storms,\n",
    "        \"Category_1_2_Hurricanes\": low_category_hurricanes,\n",
    "        \"Category_3_4_5_Hurricanes\": high_category_hurricanes\n",
    "    }\n",
    "\n",
    "    all_profiles = {}\n",
    "\n",
    "    for category_name, storms in categories.items():\n",
    "        all_radial_values = []\n",
    "        max_radius = 600 / 10  # 600 km converted to grid cells\n",
    "\n",
    "        for _ in range(int(max_radius)):\n",
    "            all_radial_values.append([])\n",
    "\n",
    "        print(f\"Processing {category_name}\")\n",
    "\n",
    "        for _, storm in storms.iterrows():\n",
    "            storm_id = storm['Number']\n",
    "            datetime_str = storm['datetime'].strftime('%m_%d_%H_%M')\n",
    "\n",
    "            # Match the corresponding NetCDF file\n",
    "            nc_file_pattern = f\"{storm_id}_{datetime_str}_.*\\.nc\"\n",
    "            matching_files = [f for f in os.listdir(directory) if re.search(nc_file_pattern, f)]\n",
    "\n",
    "            if not matching_files:\n",
    "                #print(f\"No matching files for storm {storm_id} at {datetime_str}\")\n",
    "                continue\n",
    "\n",
    "            for file in matching_files:\n",
    "                #print(f\"Processing file: {file}\")\n",
    "                file_path = os.path.join(directory, file)\n",
    "                data = xr.open_dataset(file_path)\n",
    "                precip = data['precip'].values\n",
    "\n",
    "                # Replace negative values with zero\n",
    "                precip[precip < 0] = 0\n",
    "\n",
    "                center = (precip.shape[0] // 2, precip.shape[1] // 2)\n",
    "                y, x = np.ogrid[:precip.shape[0], :precip.shape[1]]\n",
    "                distance_from_center = np.sqrt((x - center[1]) ** 2 + (y - center[0]) ** 2)\n",
    "                #print(distance_from_center)\n",
    "                for radius in range(int(max_radius)):\n",
    "                    mask = (distance_from_center >= radius) & (distance_from_center < radius + 1)\n",
    "                    values = precip[mask]\n",
    "                    values = values[~np.isnan(values)]\n",
    "                    all_radial_values[radius].extend(values)\n",
    "        mean_values = [np.mean(values) if len(values) > 0 else 0 for values in all_radial_values]\n",
    "        conf_intervals = [\n",
    "            stats.t.interval(\n",
    "                0.99,\n",
    "                len(values) - 1,\n",
    "                loc=np.mean(values),\n",
    "                scale=stats.sem(values)\n",
    "            ) if len(values) > 1 else (0, 0)\n",
    "            for values in all_radial_values\n",
    "        ]\n",
    "\n",
    "        lower_bound = [ci[0] if ci[0] > 0 else 0 for ci in conf_intervals]\n",
    "        upper_bound = [ci[1] if ci[1] > 0 else 0 for ci in conf_intervals]\n",
    "\n",
    "        all_profiles[category_name] = (mean_values, lower_bound, upper_bound)\n",
    "\n",
    "    return all_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53ac50-86e3-41da-9b3f-09812cee675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/scratch/09295/naveens/rotated_data_hurricane/unmasked/\"\n",
    "profiles = process_directory_for_profiles(directory, bth, storm_id)\n",
    "plot_combined_radial_profiles(profiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
